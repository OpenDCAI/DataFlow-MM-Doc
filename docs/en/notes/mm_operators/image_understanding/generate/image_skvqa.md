---

title: Image-based Knowledge-Enhanced Question Answering Generation (SKVQA)
createTime: 2025/10/26 15:00:00
icon: material-symbols-light:image
permalink: /en/mm_operators/generate/image_skvqa/
---

## üìò Overview

`ImageSKVQAGenerate` is an operator designed to generate **Synthetic Knowledge Visual Question Answering (SKVQA)** data.
Unlike standard Visual Question Answering (VQA), SKVQA integrates external **contextual knowledge** into the question‚Äìanswer generation process,
enabling the model to reason based not only on the image itself but also on relevant textual descriptions or background information.

This capability is highly useful for **visual knowledge understanding, product manual QA generation, and multimodal knowledge-enhanced training** tasks.

---

## üèóÔ∏è `__init__` Function

```python
def __init__(
    self,
    llm_serving: LLMServingABC
):
    ...
```

## üßæ `__init__` Parameters

| Parameter     | Type            | Default | Description                                                                               |
| :------------ | :-------------- | :------ | :---------------------------------------------------------------------------------------- |
| `llm_serving` | `LLMServingABC` | -       | The model serving object used to call a Vision-Language Model (VLM) for SKVQA generation. |

---

## ‚ö° `run` Function

```python
def run(
    self,
    storage: DataFlowStorage,
    multi_modal_key: str = "image",
    output_key: str = "skvqa"
):
    ...
```

Executes the main operator logic to generate structured SKVQA outputs ‚Äî including contextual text (`context`) and question‚Äìanswer pairs (`QAs`) ‚Äî for each input image.

---

## üßæ `run` Parameters

| Parameter         | Type              | Default   | Description                                                  |
| :---------------- | :---------------- | :-------- | :----------------------------------------------------------- |
| `storage`         | `DataFlowStorage` | -         | The DataFlow storage object.                                 |
| `multi_modal_key` | `str`             | `"image"` | The multimodal input field name (usually the image path).    |
| `output_key`      | `str`             | `"skvqa"` | The output field name used to store the parsed SKVQA result. |

---

## üß† Operator Functionality

* Automatically generates a structured **SKVQA output** for each image, containing:

  * `context`: Contextual background information or knowledge relevant to the image.
  * `qas`: A list of question‚Äìanswer pairs (`question`, `answer`).

* Parses model outputs formatted in Markdown, such as:

  ```
  ### Wikipedia Article
  (context text)

  ### Question Answer Pairs
  1. **Question**
     - Answer
  2. **Question**
     - Answer
  ```

* Supports **fault-tolerant parsing**, meaning even imperfectly formatted text can be interpreted as best as possible.

* Applicable for **visual knowledge enhancement, multimodal training, and QA generation** tasks.

---

## üß© Example Usage

```python
from dataflow.utils.storage import FileStorage
from dataflow.serving.local_model_vlm_serving import LocalModelVLMServing_vllm
from dataflow.operators.core_vision.generate.sk_vqa_generator import ImageSKVQAGenerate

# Step 1: Launch a local vision-language model
serving = LocalModelVLMServing_vllm(
    hf_model_name_or_path="./models/Qwen2.5-VL-3B-Instruct",
    vllm_tensor_parallel_size=1,
    vllm_temperature=0.7,
    vllm_top_p=0.9,
    vllm_max_tokens=512
)

# Step 2: Prepare input data
storage = FileStorage(
    first_entry_file_name="data/example_skvqa.jsonl",
    cache_path="./cache_skvqa",
    cache_type="jsonl"
)
storage.step()

# Step 3: Initialize the operator and run it
skvqa_generator = ImageSKVQAGenerate(serving)
skvqa_generator.run(
    storage=storage,
    multi_modal_key="image",
    output_key="skvqa"
)
```

---

## üßæ Default Output Format

| Field   | Type             | Description                                                                          |
| :------ | :--------------- | :----------------------------------------------------------------------------------- |
| `image` | `List[str]`      | List of input image paths.                                                           |
| `skvqa` | `Dict[str, Any]` | The structured SKVQA output generated by the model, including context and Q&A pairs. |

---

### üì• Example Input

```jsonl
{"image": ["./data/product_manual.jpg"]}
```

### üì§ Example Output

```jsonl
{
  "image": ["./data/product_manual.jpg"],
  "skvqa": {
    "context": "This is a section from a smartwatch user manual showing the health monitoring interface.",
    "qas": [
      {"question": "What device is shown in the image?", "answer": "A smartwatch"},
      {"question": "What are its main features?", "answer": "It supports heart rate monitoring, step tracking, and sleep analysis."},
      {"question": "What is the main topic of this text?", "answer": "An introduction to smartwatch functions"}
    ]
  }
}
```

---

## üí° Key Features

* ‚úÖ Supports batch image inputs
* ‚úÖ Automatically generates structured context + Q&A results
* ‚úÖ Built-in format cleaning and fault tolerance
* ‚úÖ Compatible with any vision‚Äìlanguage model (e.g., Qwen-VL, InternVL, MiniCPM-V)
* ‚úÖ Ideal for multimodal knowledge enhancement, retrieval QA, and data generation tasks
