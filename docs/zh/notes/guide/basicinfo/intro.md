---
title: 简介
icon: mdi:tooltip-text-outline
createTime: 2025/06/13 14:51:34
permalink: /zh/guide/intro/basicinfo/intro/
---
# 简介
近年来，大模型的发展在很大程度上依赖于大规模、高质量的训练数据。然而，目前主流的训练数据及其处理流程多未公开，公开数据资源的规模和质量仍有限，给社区在构建和优化大模型训练数据的过程中带来不小挑战。

尽管已有如 Open-DataLab 等组织推动数据集的开源，大模型数据准备仍然是一个高度依赖手工和分散实现的过程。现阶段，不同团队往往需要各自构建清洗与构造流程，缺乏统一、系统化的工具支持。随着大模型技术的飞速发展，Agent技术逐渐应用于各行各业，使基于大模型完成高效，低成本的数据治理成为可能。然而已有数据处理工具（如Hadoop和Spark）大多以传统方法为核心，尚未对大模型的自动化数据治理进行集成和优化，对于高效构建适用于大模型训练的数据支持仍显不足。

为此，我们提出了 **DataFlow**——一个由先进算子（Operators）与多阶段数据处理流水线（Pipeline） 组成的高效数据准备系统。DataFlow 充分结合了规则方法、深度学习模型和大模型的能力，提供了可扩展、可重组的模块化设计，旨在提升数据清洗、增强与构建的质量与效率，助力下一代大模型的发展。

## DataFlow：一个高质量数据准备系统

**DataFlow** 是一个高效完成高质量数据治理的系统，旨在对诸如 PDF 文档、纯文本、爬虫数据等低质量而嘈杂的数据进行 **修正、扩增、评估与过滤**（refine, generate, evaluate, filt） 以得到高质量的训练数据。这些数据可以通过预训练、有监督微调、强化学习训练提升大语言模型在通用领域（推理能力和检索能力）与特定领域（如医疗、金融、法律等）的性能。此外，Dataflow产出的高质量数据也可以有效赋能现有的RAG系统。

具体而言，DataFlow系统由如下部分组成：
1. **算子（Operator）：**：我们对于多种数据治理需求进行了分析与抽象，构建了一系列多样化的算子，这些算子基于规则方法、深度学习模型、大语言模型（LLMs）以及 LLM API 开发而成。算子具有原子性，便于复用和框架级别统一优化。
2. **流水线（Pipeline）：**：为了实现具体的数据治理功能，将算子经过有序连接即可构建完整的流水线应用于具体场景。Dataflow中预设了相当数量的流水线服务于多种领域功能，用户可灵活增删预设流水线中的算子以满足定制化需求。
3. **提示词和提示词模板（Prompt & Prompt Template）**：针对于大模型数据治理，有些微妙的需求是不足以单独设置新算子的。这时候就需要通过替换不同的提示词模板来达成需求。这时就需要对所有的提示词和提示词模板进行注册。并建立算子到可选提示词or提示词模板的映射。便于用户查阅或由Agent调用。

经过合理的编排和组装，这些经过抽象和复用的算子和提示词模板即可系统性地整合进数据处理流水线中，满足多样化的数据治理需求。

此外，我们还提供了智能的**Dataflow-Agent**，能够根据自然语言需求动态组合已有的算子，自动构建新的数据处理流程，从而实现更灵活、高效的数据构建与处理能力。

综上，算子，流水线，提示词和提示词模板，以及Dataflow-Agent构成了完整的 **DataFlow 数据治理系统**。



