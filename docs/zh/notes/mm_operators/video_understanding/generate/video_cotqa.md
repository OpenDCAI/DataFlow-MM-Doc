---
title: è§†é¢‘é“¾å¼æ€è€ƒé—®ç­”ç”Ÿæˆï¼ˆVideoCOTQAGeneratorï¼‰
createTime: 2025/12/20 10:30:00
permalink: /zh/mm_operators/video_understanding/generate/video_cotqa/
---

## ğŸ“˜ æ¦‚è¿°

`VideoCOTQAGenerator` æ˜¯ä¸€ä¸ªç”¨äº **ç”Ÿæˆå¸¦æœ‰é“¾å¼æ€è€ƒï¼ˆChain-of-Thought, CoTï¼‰æ¨ç†è¿‡ç¨‹çš„è§†é¢‘/å›¾åƒé—®ç­”æ•°æ®** çš„ç®—å­ã€‚  
å®ƒä¼šæ ¹æ®è¾“å…¥çš„é—®é¢˜ç±»å‹ï¼ˆé€‰æ‹©é¢˜ã€æ•°å€¼é¢˜ã€OCRç­‰ï¼‰è‡ªåŠ¨æ„å»ºæç¤ºè¯ï¼Œå¼•å¯¼æ¨¡å‹è¾“å‡ºç»“æ„åŒ–çš„æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆï¼Œé€‚ç”¨äºå¤šæ¨¡æ€æ¨ç†æ•°æ®é›†æ„å»ºã€è§†é¢‘ç†è§£è¯„æµ‹ç­‰åœºæ™¯ã€‚

---

## ğŸ—ï¸ `__init__` å‡½æ•°

```python
def __init__(
    self,
    vlm_serving: VLMServingABC,
    prompt_template: Optional[VideoCOTQAGeneratorPrompt | DiyVideoPrompt | str] = None,
):
    ...
```

## ğŸ§¾ `__init__` å‚æ•°è¯´æ˜

| å‚æ•°å              | ç±»å‹                                                               | é»˜è®¤å€¼    | è¯´æ˜                                    |
| :--------------- | :--------------------------------------------------------------- | :----- | :------------------------------------ |
| `vlm_serving`    | `VLMServingABC`                                                  | -      | VLMæ¨¡å‹æœåŠ¡å¯¹è±¡ï¼Œç”¨äºè°ƒç”¨è§†è§‰è¯­è¨€æ¨¡å‹ç”ŸæˆCoTæ¨ç†å’Œç­”æ¡ˆ       |
| `prompt_template` | `VideoCOTQAGeneratorPrompt` \| `DiyVideoPrompt` \| `str` \| `None` | `None` | Promptæ¨¡æ¿ï¼Œé»˜è®¤ä½¿ç”¨ `VideoCOTQAGeneratorPrompt` |

---

## âš¡ `run` å‡½æ•°

```python
def run(
    self,
    storage: DataFlowStorage,
    input_video_key: str = "video",
    input_image_key: str = "image",
    input_conversation_key: str = "conversation",
    output_answer_key: str = "answer",
    output_process_key: str = "process",
    output_full_response_key: str = "full_response",
):
    ...
```

`run` æ˜¯ç®—å­ä¸»é€»è¾‘ï¼Œæ‰§è¡ŒCoTé—®ç­”ç”Ÿæˆä»»åŠ¡ï¼š
è¯»å–é—®é¢˜å’Œå¤šæ¨¡æ€æ•°æ® â†’ æ„å»ºCoTæç¤ºè¯ â†’ è°ƒç”¨VLMç”Ÿæˆæ¨ç†è¿‡ç¨‹ â†’ æå–æ€è€ƒé“¾å’Œç­”æ¡ˆ â†’ å†™å…¥è¾“å‡ºæ–‡ä»¶ã€‚

## ğŸ§¾ `run` å‚æ•°è¯´æ˜

| å‚æ•°å                       | ç±»å‹                | é»˜è®¤å€¼               | è¯´æ˜                          |
| :------------------------ | :---------------- | :---------------- | :-------------------------- |
| `storage`                 | `DataFlowStorage` | -                 | Dataflow æ•°æ®å­˜å‚¨å¯¹è±¡             |
| `input_video_key`         | `str`             | `"video"`         | è¾“å…¥æ•°æ®ä¸­è§†é¢‘å­—æ®µå                  |
| `input_image_key`         | `str`             | `"image"`         | è¾“å…¥æ•°æ®ä¸­å›¾åƒå­—æ®µå                  |
| `input_conversation_key`  | `str`             | `"conversation"`  | è¾“å…¥æ•°æ®ä¸­å¯¹è¯å­—æ®µå                  |
| `output_answer_key`       | `str`             | `"answer"`        | æ¨¡å‹è¾“å‡ºçš„æœ€ç»ˆç­”æ¡ˆå­—æ®µå                |
| `output_process_key`      | `str`             | `"process"`       | æ¨¡å‹è¾“å‡ºçš„æ€è€ƒè¿‡ç¨‹å­—æ®µåï¼ˆåŒ…å« `<think>` æ ‡ç­¾ï¼‰ |
| `output_full_response_key` | `str`             | `"full_response"` | æ¨¡å‹è¾“å‡ºçš„å®Œæ•´å“åº”å­—æ®µå                |

---

## ğŸ§  ç¤ºä¾‹ç”¨æ³•

```python
from dataflow.operators.core_vision import VideoCOTQAGenerator
from dataflow.serving import LocalModelVLMServing_vllm
from dataflow.utils.storage import FileStorage

# Step 1: å¯åŠ¨æœ¬åœ°æ¨¡å‹æœåŠ¡
vlm_serving = LocalModelVLMServing_vllm(
    hf_model_name_or_path="Qwen/Qwen2.5-VL-7B-Instruct",
    hf_cache_dir="./model_cache",
    vllm_tensor_parallel_size=1,
    vllm_temperature=0.7,
    vllm_top_p=0.9,
    vllm_max_tokens=4096,
    vllm_max_model_len=51200,
    vllm_gpu_memory_utilization=0.9
)

# Step 2: å‡†å¤‡è¾“å…¥æ•°æ®
storage = FileStorage(
    first_entry_file_name="./cot_qa_data.json",
    cache_path="./cache",
    file_name_prefix="video_cotqa",
    cache_type="json",
)
storage.step()

# Step 3: åˆå§‹åŒ–å¹¶è¿è¡Œç®—å­
cotqa_generator = VideoCOTQAGenerator(
    vlm_serving=vlm_serving,
)
cotqa_generator.run(
    storage=storage,
    input_video_key="video",
    input_conversation_key="conversation",
    output_answer_key="answer",
    output_process_key="process",
    output_full_response_key="full_response"
)
```

---

## ğŸ§¾ è¾“å…¥æ ¼å¼è¦æ±‚ï¼ˆInput Formatï¼‰

| å­—æ®µ             | ç±»å‹           | è¯´æ˜                                                       |
| :------------- | :----------- | :------------------------------------------------------- |
| `problem_type` | `str`        | é—®é¢˜ç±»å‹ï¼š`multiple choice`ã€`numerical`ã€`OCR`ã€`free-form`ã€`regression` |
| `problem`      | `str`        | é—®é¢˜æ–‡æœ¬                                                     |
| `options`      | `List[str]`  | é€‰é¡¹åˆ—è¡¨ï¼ˆä»…é€‚ç”¨äºé€‰æ‹©é¢˜ï¼‰                                            |
| `data_type`    | `str`        | æ•°æ®ç±»å‹ï¼š`video` æˆ– `image`                                   |
| `video`        | `List[str]`  | è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå½“ `data_type` ä¸º `video` æ—¶ï¼‰                      |
| `image`        | `List[str]`  | å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå½“ `data_type` ä¸º `image` æ—¶ï¼‰                      |
| `solution`     | `str`        | æ ‡å‡†ç­”æ¡ˆï¼ˆåŒ…å« `<answer>` æ ‡ç­¾ï¼‰                                   |
| `conversation` | `List[Dict]` | å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼Œä¼šè¢«è‡ªåŠ¨åˆ›å»ºæˆ–æ›´æ–°ï¼‰                                       |

---

### ğŸ“¥ ç¤ºä¾‹è¾“å…¥

```json
{
  "problem_type": "multiple choice",
  "problem": "è§†é¢‘ä¸­çš„äººåœ¨åšä»€ä¹ˆï¼Ÿ",
  "options": ["A. è·‘æ­¥", "B. æ¸¸æ³³", "C. éª‘è‡ªè¡Œè½¦", "D. è·³èˆ"],
  "data_type": "video",
  "video": ["./test/example_video.mp4"],
  "solution": "<answer>C</answer>",
  "conversation": [{"from": "human", "value": ""}]
}
```

### ğŸ“¤ ç¤ºä¾‹è¾“å‡º

```json
{
  "problem_type": "multiple choice",
  "problem": "è§†é¢‘ä¸­çš„äººåœ¨åšä»€ä¹ˆï¼Ÿ",
  "options": ["A. è·‘æ­¥", "B. æ¸¸æ³³", "C. éª‘è‡ªè¡Œè½¦", "D. è·³èˆ"],
  "data_type": "video",
  "video": ["./test/example_video.mp4"],
  "solution": "<answer>C</answer>",
  "conversation": [
    {
      "from": "human",
      "value": "è§†é¢‘ä¸­çš„äººåœ¨åšä»€ä¹ˆï¼ŸOptions:\nA. è·‘æ­¥\nB. æ¸¸æ³³\nC. éª‘è‡ªè¡Œè½¦\nD. è·³èˆ\n"
    }
  ],
  "answer": "C",
  "process": "<think>é¦–å…ˆè§‚å¯Ÿè§†é¢‘ä¸­çš„ä¸»è¦æ´»åŠ¨ã€‚è§†é¢‘æ˜¾ç¤ºä¸€ä¸ªäººéª‘ç€è‡ªè¡Œè½¦åœ¨å…¬å›­é‡Œã€‚ä»åŠ¨ä½œå’Œåœºæ™¯æ¥çœ‹ï¼Œè¿™æ˜¯å…¸å‹çš„éª‘è‡ªè¡Œè½¦æ´»åŠ¨ã€‚å› æ­¤ç­”æ¡ˆåº”è¯¥æ˜¯Cã€‚</think>",
  "full_response": "<think>é¦–å…ˆè§‚å¯Ÿè§†é¢‘ä¸­çš„ä¸»è¦æ´»åŠ¨ã€‚è§†é¢‘æ˜¾ç¤ºä¸€ä¸ªäººéª‘ç€è‡ªè¡Œè½¦åœ¨å…¬å›­é‡Œã€‚ä»åŠ¨ä½œå’Œåœºæ™¯æ¥çœ‹ï¼Œè¿™æ˜¯å…¸å‹çš„éª‘è‡ªè¡Œè½¦æ´»åŠ¨ã€‚å› æ­¤ç­”æ¡ˆåº”è¯¥æ˜¯Cã€‚</think>\n<answer>C</answer>"
}
```

---

## ğŸ¯ æ”¯æŒçš„é—®é¢˜ç±»å‹

### 1. é€‰æ‹©é¢˜ (multiple choice)
- è‡ªåŠ¨æ ¼å¼åŒ–é€‰é¡¹åˆ—è¡¨
- æå–å•ä¸ªå­—æ¯æˆ–çŸ­æ–‡æœ¬ç­”æ¡ˆ

### 2. æ•°å€¼é¢˜ (numerical)
- é€‚ç”¨äºéœ€è¦è®¡ç®—çš„é—®é¢˜
- æå–æ•°å€¼ç­”æ¡ˆ

### 3. OCR é—®é¢˜
- é€‚ç”¨äºæ–‡å­—è¯†åˆ«ä»»åŠ¡
- æå–è¯†åˆ«çš„æ–‡æœ¬

### 4. è‡ªç”±å½¢å¼ (free-form)
- å¼€æ”¾å¼é—®ç­”
- æå–å®Œæ•´æ–‡æœ¬ç­”æ¡ˆ

### 5. å›å½’é—®é¢˜ (regression)
- é€‚ç”¨äºè¿ç»­å€¼é¢„æµ‹
- æå–æ•°å€¼æˆ–èŒƒå›´ç­”æ¡ˆ

---

## ğŸ¨ è‡ªå®šä¹‰ Prompt

é»˜è®¤ä½¿ç”¨ `VideoCOTQAGeneratorPrompt` ç±»ï¼Œå…¶ prompt æ ¼å¼ä¸ºï¼š

```
{Question}

Please think about this question as if you were a human pondering deeply. Engage in an internal dialogue using expressions such as 'let me think', 'wait', 'Hmm', 'oh, I see', 'let's break it down', etc, or other natural language thought expressions. It's encouraged to include self-reflection or verification in the reasoning process. Provide your detailed reasoning between the <think> and </think> tags, and then give your final answer between the <answer> and </answer> tags.
```

è¯¥ prompt å¼•å¯¼æ¨¡å‹åƒäººç±»ä¸€æ ·æ·±å…¥æ€è€ƒï¼Œä½¿ç”¨è‡ªç„¶è¯­è¨€æ€ç»´è¡¨è¾¾ï¼ˆå¦‚"è®©æˆ‘æƒ³æƒ³"ã€"ç­‰ç­‰"ã€"å—¯"ã€"å“¦ï¼Œæˆ‘æ˜ç™½äº†"ç­‰ï¼‰ï¼Œå¹¶é¼“åŠ±åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŒ…å«è‡ªæˆ‘åæ€æˆ–éªŒè¯

### æ–¹å¼1ï¼šä½¿ç”¨å­—ç¬¦ä¸²

```python
cotqa_generator = VideoCOTQAGenerator(
    vlm_serving=vlm_serving,
    prompt_template="è¯·åˆ†æé—®é¢˜å¹¶ç”¨<think>æ ‡ç­¾åŒ…è£¹æ¨ç†è¿‡ç¨‹ï¼Œç”¨<answer>æ ‡ç­¾åŒ…è£¹æœ€ç»ˆç­”æ¡ˆã€‚é—®é¢˜ï¼š{Question}"
)
```

### æ–¹å¼2ï¼šä½¿ç”¨è‡ªå®šä¹‰Promptç±»

```python
from dataflow.prompts.video import DiyVideoPrompt

custom_prompt = DiyVideoPrompt(
    "Analyze the question step by step:\n{Question}\n\nFormat: <think>reasoning</think>\n<answer>final answer</answer>"
)

cotqa_generator = VideoCOTQAGenerator(
    vlm_serving=vlm_serving,
    prompt_template=custom_prompt
)
```

---

## ğŸ”— ç›¸å…³é“¾æ¥

- **ä»£ç :** [VideoCOTQAGenerator](https://github.com/OpenDCAI/DataFlow-MM/blob/main/dataflow/operators/core_vision/generate/video_cotqa_generator.py)
- **ç›¸å…³ç®—å­:**
  - [VideoToCaptionGenerator](./video_caption.md) - è§†é¢‘æè¿°ç”Ÿæˆ
  - [VideoCaptionToQAGenerator](./video_qa.md) - è§†é¢‘é—®ç­”ç”Ÿæˆ
  - [GeneralTextAnswerEvaluator](../eval/general_text_answer_evaluator.md) - ç­”æ¡ˆè¯„ä¼°

