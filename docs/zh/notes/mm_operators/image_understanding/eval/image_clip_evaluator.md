---
title: ImageCLIPEvaluator
createTime: 2025/10/15 13:47:08
# icon: material-symbols-light:image
permalink: /zh/mm_operators/eval/image_clip_evaluator/
---
## ğŸ“˜ æ¦‚è¿°
`ImageCLIPEvaluator` åŸºäº **CLIP** è®¡ç®—å›¾åƒä¸æ–‡æœ¬çš„**å¯¹é½åˆ†æ•°**ï¼ŒèŒƒå›´ `[0,1]`ã€‚  
å†…éƒ¨åšæ³•ï¼šå¯¹å›¾åƒä¸æ–‡æœ¬ç¼–ç  â†’ å‘é‡å½’ä¸€åŒ– â†’ ä½™å¼¦ç›¸ä¼¼åº¦çº¿æ€§æ˜ å°„åˆ° `[0,1]`ï¼ˆ`(cos + 1)/2`ï¼‰ã€‚



## ```__init__```å‡½æ•°
```python
def __init__(
    self,
    model_name: str = "openai/clip-vit-base-patch32",
    device: str = None
):
```

## `init`å‚æ•°è¯´æ˜
| å‚æ•°å       | ç±»å‹          | é»˜è®¤å€¼                               | è¯´æ˜ |
| :----------- | :------------ | :----------------------------------- | :--- |
| `model_name` | `str`         | `"openai/clip-vit-base-patch32"`    | CLIP æ¨¡å‹æœ¬åœ°è·¯å¾„æˆ– HF Model IDï¼›é€šè¿‡ `CLIPProcessor` / `CLIPModel` åŠ è½½ï¼ˆ`use_safetensors=True`ï¼‰ã€‚ |
| `device`     | `str \| None` | `None`                              | æ¨ç†è®¾å¤‡ï¼›`None` æ—¶è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„ `"cuda"`ï¼Œå¦åˆ™ä½¿ç”¨ `"cpu"`ã€‚ |


## `run`å‡½æ•°
```python
def run(
    self,
    storage: DataFlowStorage,
    input_image_key: str = "image_path",
    input_text_key: str = "text",
    output_key: str = "clip_score"
):
    ...
```
æ‰§è¡Œç®—å­ä¸»é€»è¾‘
1. ä» `storage` è¯»å–å½“å‰ DataFrameï¼Œé€è¡Œè¯»å– `input_image_key` ä¸ `input_text_key` å¯¹åº”çš„å€¼ã€‚  
2. ä½¿ç”¨ `CLIPProcessor` ç»„è£…è¾“å…¥ï¼ˆ`padding="max_length"`, `truncation=True`, `max_length=77`ï¼‰ï¼Œå‰å‘å¾—åˆ° `image_embeds` ä¸ `text_embeds`ã€‚  
3. å¯¹åµŒå…¥å‘é‡åš L2 å½’ä¸€åŒ–ï¼Œè®¡ç®—ç‚¹ç§¯å¾—åˆ°ä½™å¼¦ç›¸ä¼¼åº¦ `cos`ï¼Œå¹¶æ˜ å°„ä¸ºå¯¹é½åˆ†æ•°`score = (cos + 1) / 2`ï¼Œå†è£å‰ªåˆ° `[0,1]` åŒºé—´ã€‚  
4. å°†åˆ†æ•°å†™å…¥æ–°åˆ— `output_key`ï¼Œå†™å› `storage`ï¼Œå¹¶è¿”å› `[output_key]`ã€‚  
5. è‹¥å›¾ç‰‡æ— æ³•è¯»å–æˆ–æ–‡æœ¬ä¸ºç©ºï¼Œåˆ™è¯¥æ ·æœ¬åˆ†æ•°è®°ä¸º `0.0`ã€‚

å‚æ•°
| å‚æ•°å            | ç±»å‹              | é»˜è®¤å€¼           | è¯´æ˜ |
| :---------------- | :---------------- | :--------------- | :--- |
| `storage`         | `DataFlowStorage` | æ—                | Dataflow çš„è¯»å†™å­˜å‚¨å¯¹è±¡ã€‚ |
| `input_image_key` | `str`             | `"image_path"`   | è¾“å…¥å›¾ç‰‡åˆ—åã€‚ |
| `input_text_key`  | `str`             | `"text"`         | è¾“å…¥æ–‡æœ¬åˆ—åã€‚ |
| `output_key`      | `str`             | `"clip_score"`   | è¾“å‡ºåˆ†æ•°å­—æ®µåï¼ˆèŒƒå›´ `[0,1]`ï¼‰ã€‚ |

## ğŸ§  ç¤ºä¾‹ç”¨æ³•

```python
from dataflow.utils.storage import FileStorage
from dataflow.operators.core_vision import ImageCLIPEvaluator

# 1) å‡†å¤‡ FileStorageï¼ˆè‡³å°‘åŒ…å« image_path ä¸ text ä¸¤åˆ—ï¼‰
storage = FileStorage(
    first_entry_file_name="./dataflow/example/test_image_eval/test_image_eval.jsonl",
    cache_path="./cache_local",
    file_name_prefix="clip_eval",
    cache_type="jsonl"
)

# 2) åˆå§‹åŒ–ç®—å­ï¼ˆå¯æ”¹ä¸º HF æ¨¡å‹IDï¼Œå¦‚ "openai/clip-vit-base-patch32"ï¼‰
evaluator = ImageCLIPEvaluator(
    model_name="openai/clip-vit-base-patch32",
    device=None  # è‡ªåŠ¨é€‰æ‹© cuda/cpu
)

# 3) æ‰§è¡Œè¯„ä¼°
cols = evaluator.run(
    storage=storage.step(),
    input_image_key="image_path",
    input_text_key="text",
    output_key="clip_score"
)
print(cols)  # ["clip_score"]
```

### ğŸ§¾ é»˜è®¤è¾“å‡ºæ ¼å¼ï¼ˆOutput Formatï¼‰
| å­—æ®µå                                      | ç±»å‹     | é»˜è®¤å€¼ | è¯´æ˜ |
| :------------------------------------------ | :------- | :----- | :--- |
| `image_path`ï¼ˆæˆ– `input_image_key` æŒ‡å®šåˆ—ï¼‰ | `string` | æ—      | è¾“å…¥å›¾ç‰‡è·¯å¾„ã€‚ |
| `text`ï¼ˆæˆ– `input_text_key` æŒ‡å®šåˆ—ï¼‰        | `string` | æ—      | è¾“å…¥æ–‡æœ¬ã€‚ |
| `clip_score`ï¼ˆæˆ– `output_key`ï¼‰             | `float`  | æ—      | å›¾æ–‡å¯¹é½åˆ†æ•°ï¼ŒèŒƒå›´ `[0,1]`ã€‚ |



ç¤ºä¾‹è¾“å…¥ï¼š
```jsonl
{
  "image_path": "1.png",
  "text": "The image shows a man and a woman in what appears to be a car."
}
```

ç¤ºä¾‹è¾“å‡ºï¼š
```jsonl
{
  "image_path": "1.png",
  "text": "The image shows a man and a woman in what appears to be a car.",
  "clip_score": 0.642
}
```