---
title: æ–‡æœ¬è‡ªç„¶åº¦è¿‡æ»¤ï¼ˆCatFilterï¼‰
createTime: 2025/10/15 15:00:00
icon: material-symbols-light:image
permalink: /zh/mm_operators/filter/image_cat_filter/
---
## ğŸ“˜ æ¦‚è¿°
`ImageCatFilter` åŸºäº **Caption-as-Teacher** æ€æƒ³ï¼Œç»“åˆ **BART-large-MNLI è‡ªç„¶è¯­è¨€æ¨ç†æ¨¡å‹** ä¸å¯é€‰çš„ **Tesseract OCR**ï¼Œ  
å¯¹å›¾æ–‡æ ·æœ¬è¿›è¡Œã€Œè¯­ä¹‰å¤æ‚åº¦ + åŠ¨ä½œæ€§ + OCR æŠ„å†™ã€ä¸‰é‡è¿‡æ»¤ï¼Œä»…ä¿ç•™è¯­ä¹‰ä¿¡æ¯æ›´ä¸°å¯Œã€çœŸæ­£æè¿°å›¾åƒå†…å®¹çš„ captionã€‚

## ```__init__```å‡½æ•°
```python
def __init__(
    self,
    model_name: str = "facebook/bart-large-mnli",
    complexity_thresh: float = 0.4,
    min_caps: int = 2,
    action_thresh: float = 0.4,
    ocr_overlap_threshold: float = 0.2,
    ocr_nli_thresh: float = 0.6,
    device: str | None = None,
):
```

## `init`å‚æ•°è¯´æ˜
| å‚æ•°å                 | ç±»å‹              | é»˜è®¤å€¼                          | è¯´æ˜ |
| :--------------------- | :---------------- | :------------------------------ | :--- |
| `model_name`           | `str`             | `"facebook/bart-large-mnli"`    | ç”¨äº NLI åˆ¤æ–­çš„é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„ï¼›é€šè¿‡ `AutoTokenizer` ä¸ `AutoModelForSequenceClassification` åŠ è½½ã€‚ |
| `complexity_thresh`    | `float`           | `0.4`                           | caption å¯¹å„ç±»ã€Œèƒ½åŠ›å‡è®¾å¥ã€çš„ **è•´å«æ¦‚ç‡é˜ˆå€¼**ï¼›é«˜äºè¯¥å€¼è§†ä¸ºè¯¥èƒ½åŠ›è¢« caption è¦†ç›–ï¼Œç”¨äºè¡¡é‡è¯­ä¹‰å¤æ‚åº¦ã€‚ |
| `min_caps`             | `int`             | `2`                             | è‡³å°‘éœ€è¦è¢«æ”¯æŒçš„èƒ½åŠ›å‡è®¾æ¡æ•°ï¼›å³ caption è‡³å°‘è¦è•´å«å¤šå°‘ç§èƒ½åŠ›ï¼ˆåŠ¨ä½œã€äº¤äº’ã€åœºæ™¯ç»†èŠ‚ç­‰ï¼‰æ‰ç®—â€œå¤æ‚åº¦è¾¾æ ‡â€ã€‚ |
| `action_thresh`        | `float`           | `0.4`                           | caption å¯¹ `ACTION_HYPOTHESIS`ï¼ˆæè¿°åœºæ™¯ä¸­æ­£åœ¨å‘ç”Ÿçš„åŠ¨ä½œï¼‰çš„è•´å«æ¦‚ç‡é˜ˆå€¼ï¼›ä½äºè¯¥å€¼è®¤ä¸ºåŠ¨ä½œæ€§ä¸è¶³è€Œè¢«è¿‡æ»¤ã€‚ |
| `ocr_overlap_threshold`| `float`           | `0.2`                           | OCR æ–‡æœ¬ä¸ caption tokens çš„ Jaccard é‡å åº¦é˜ˆå€¼ï¼›ä»…å½“é‡å åº¦é«˜äºè¯¥å€¼æ—¶æ‰è¿›ä¸€æ­¥ç”¨ NLI åˆ¤æ–­æ˜¯å¦ä¸º OCR æŠ„å†™ã€‚ |
| `ocr_nli_thresh`       | `float`           | `0.6`                           | caption å¯¹ `OCR_ONLY_HYPOTHESIS`ï¼ˆä¸»è¦æŠ„å†™å›¾åƒæ–‡å­—ï¼‰çš„è•´å«æ¦‚ç‡é˜ˆå€¼ï¼›é‡å åº¦é«˜ä¸”è¯¥æ¦‚ç‡è¶…è¿‡æ­¤é˜ˆå€¼æ—¶ï¼Œåˆ¤å®šä¸º OCR æŠ„å†™å¹¶è¿‡æ»¤ã€‚ |
| `device`               | `str \| None`     | `None`   


## `run`å‡½æ•°
```python
def run(
    self,
    storage: DataFlowStorage,
    input_image_key: str = "image",
    input_caption_key: str = "caption",
):
    ...
```
æ‰§è¡Œç®—å­ä¸»é€»è¾‘ï¼š
1. **è¯»å–æ•°æ®**  
   ä» `storage` ä¸­è¯»å–å½“å‰ DataFrameï¼Œå¹¶æŒ‰è¡Œéå†ï¼Œæ¯ä¸€è¡Œè§†ä¸ºä¸€ä¸ªå›¾æ–‡æ ·æœ¬ï¼š  
   - `input_image_key` åˆ—ç»™å‡ºå›¾åƒè·¯å¾„ï¼ˆé»˜è®¤ `"image"`ï¼‰ï¼›  
   - `input_caption_key` åˆ—ç»™å‡ºè‹±æ–‡ captionï¼ˆé»˜è®¤ `"caption"`ï¼‰ã€‚

2. **å¤æ‚åº¦æ£€æµ‹ï¼ˆComplexity checkï¼‰**  
   - å¯¹å½“å‰ captionï¼Œä¾æ¬¡ä¸ `CAPS_HYPOTHESES` ä¸­çš„æ¯æ¡ã€Œèƒ½åŠ›å‡è®¾å¥ã€ç»„æˆ NLI å‰æ-å‡è®¾å¯¹ï¼š  
     `premise = caption`ï¼Œ`hypothesis = æŸæ¡èƒ½åŠ›å¥`ã€‚  
   - ç”¨ `BART-large-mnli` è®¡ç®—æ¯æ¡å‡è®¾çš„ **entailment æ¦‚ç‡** `p_entail`ï¼›  
   - å½“ `p_entail >= complexity_thresh` æ—¶ï¼Œè®¤ä¸ºè¯¥èƒ½åŠ›è¢« caption è¦†ç›–ï¼Œå¹¶è®¡å…¥èƒ½åŠ›è®¡æ•°ï¼›  
   - æœ€ç»ˆèƒ½åŠ›è®¡æ•° `cap_num >= min_caps` æ—¶ï¼Œè®¤ä¸º caption å…·æœ‰è¶³å¤Ÿçš„è¯­ä¹‰å¤æ‚åº¦ï¼Œå¦åˆ™è¯¥æ ·æœ¬è¢«è¿‡æ»¤ã€‚

3. **åŠ¨ä½œæ€§æ£€æµ‹ï¼ˆAction checkï¼‰**  
   - ä½¿ç”¨å•ä¸€å‡è®¾ `ACTION_HYPOTHESIS`ï¼š  
     > "The caption clearly describes an action happening in the scene."  
   - è®¡ç®— caption å¯¹è¯¥å‡è®¾çš„ entailment æ¦‚ç‡ `p_action`ï¼›  
   - å½“ `p_action < action_thresh` æ—¶ï¼Œè®¤ä¸º caption å¹¶æœªæ¸…æ™°æè¿°åŠ¨ä½œï¼Œæ ·æœ¬è¢«è¿‡æ»¤ã€‚

4. **OCR æŠ„å†™æ£€æµ‹ï¼ˆOCR-only checkï¼Œå¯é€‰ï¼‰**  
   - è‹¥æœ¬æœºæœªå®‰è£… Tesseract æˆ–åˆå§‹åŒ–æ—¶æ£€æµ‹å¤±è´¥ï¼Œåˆ™ **è·³è¿‡** æœ¬æ­¥éª¤ï¼Œé»˜è®¤é€šè¿‡ OCR æ£€æŸ¥ï¼›  
   - å¦åˆ™ï¼š  
     1. ä½¿ç”¨ `pytesseract.image_to_string` å¯¹å›¾åƒåš OCRï¼Œå¾—åˆ° `ocr_text`ï¼›  
     2. å¯¹ `ocr_text` ä¸ `caption` åˆ†åˆ«æå–è‹±æ–‡ token é›†åˆ `ocr_tokens` ä¸ `cap_tokens`ï¼›  
     3. è®¡ç®— Jaccard é‡å åº¦ï¼š  
        \[
        J = \frac{|ocr\_tokens \cap cap\_tokens|}{|ocr\_tokens \cup cap\_tokens|}
        \]  
     4. è‹¥ `J < ocr_overlap_threshold`ï¼Œè®¤ä¸º caption ä¸ä¸»è¦æŠ„å†™æ–‡å­—ï¼Œé€šè¿‡ OCR æ£€æŸ¥ï¼›  
     5. è‹¥ `J >= ocr_overlap_threshold`ï¼Œè¿›ä¸€æ­¥æ„é€  `OCR_ONLY_HYPOTHESIS`ï¼š  
        > "The caption mainly transcribes the visible text in the image instead of describing the visual scene."  
        å¹¶è®¡ç®—å…¶ entailment æ¦‚ç‡ `p_ocr_only`ï¼š  
        - è‹¥ `p_ocr_only >= ocr_nli_thresh`ï¼Œåˆ™è®¤ä¸º caption ä¸»è¦æ˜¯ OCR æŠ„å†™ï¼Œæ ·æœ¬è¢«è¿‡æ»¤ï¼›  
        - å¦åˆ™ä»è§†ä¸ºé€šè¿‡ OCR æ£€æŸ¥ã€‚

5. **ç»¼åˆåˆ¤å®š**  
   å¯¹æ¯ä¸€è¡Œæ ·æœ¬ï¼Œåªæœ‰å½“ **å¤æ‚åº¦æ£€æµ‹é€šè¿‡ + åŠ¨ä½œæ£€æµ‹é€šè¿‡ + OCR æ£€æµ‹é€šè¿‡** ä¸‰è€…åŒæ—¶æ»¡è¶³æ—¶ï¼Œ  
   æ‰å°†è¯¥è¡Œæ ‡è®°ä¸ºä¿ç•™ï¼›å¦åˆ™æ ‡è®°ä¸ºè¿‡æ»¤ã€‚


å‚æ•°
| å‚æ•°å            | ç±»å‹              | é»˜è®¤å€¼         | è¯´æ˜ |
| :---------------- | :---------------- | :------------- | :--- |
| `storage`         | `DataFlowStorage` | æ—              | Dataflow çš„è¯»å†™å­˜å‚¨å¯¹è±¡ã€‚ |
| `input_image_key` | `str`             | `"image"`      | å›¾åƒè·¯å¾„æ‰€åœ¨åˆ—åã€‚ |
| `input_caption_key` | `str`           | `"caption"`    | è‹±æ–‡å›¾åƒæè¿°æ‰€åœ¨åˆ—åã€‚ |




## ğŸ§  ç¤ºä¾‹ç”¨æ³•

```python
from dataflow.utils.storage import FileStorage
from dataflow.operators.core_vision import ImageCatFilter

# 1) å‡†å¤‡ FileStorageï¼ˆè‡³å°‘åŒ…å« image ä¸ caption ä¸¤åˆ—ï¼‰
storage = FileStorage(
    first_entry_file_name="./dataflow/example/test_image_filter/test_image_filter.jsonl",
    cache_path="./cache_local",
    file_name_prefix="cat_filter",
    cache_type="jsonl"
)

# 2) åˆå§‹åŒ– Cat è¿‡æ»¤ç®—å­ï¼ˆå¯è°ƒèŠ‚å¤æ‚åº¦é˜ˆå€¼ä¸ OCR ç›¸å…³è¶…å‚ï¼‰
cat_filter = ImageCatFilter(
    model_name="facebook/bart-large-mnli",
    complexity_thresh=0.4,
    min_caps=2,
    action_thresh=0.4,
    ocr_overlap_threshold=0.2,
    ocr_nli_thresh=0.6,
    device=None  # è‡ªåŠ¨é€‰æ‹© cuda/cpu
)

# 3) æ‰§è¡Œè¿‡æ»¤ï¼šä»…ä¿ç•™è¯­ä¹‰å¤æ‚ã€å…·æœ‰åŠ¨ä½œä¸”éçº¯ OCR æŠ„å†™çš„æ ·æœ¬
cols = cat_filter.run(
    storage=storage.step(),
    input_image_key="image",
    input_caption_key="caption",
)
print(cols)  # ["image", "caption"]
```

### ğŸ§¾ é»˜è®¤è¾“å‡ºæ ¼å¼ï¼ˆOutput Formatï¼‰
| å­—æ®µå                                          | ç±»å‹     | é»˜è®¤å€¼ | è¯´æ˜ |
| :---------------------------------------------- | :------- | :----- | :--- |
| `image`ï¼ˆæˆ– `input_image_key` æŒ‡å®šåˆ—ï¼‰          | `string` | æ—      | è¾“å…¥å›¾åƒè·¯å¾„ã€‚ |
| `caption`ï¼ˆæˆ– `input_caption_key` æŒ‡å®šåˆ—ï¼‰      | `string` | æ—      | è¾“å…¥è‹±æ–‡å›¾åƒæè¿°ã€‚ |


ç¤ºä¾‹è¾“å…¥ï¼š
```jsonl
{
  "image_path": "1.png",
  "caption": "A bride smiles while the groom points ahead inside a car, their hands resting together on the seat."
}
{
  "image_path": "2.jpg",
  "caption": "SALE SALE SALE 50% OFF"
}
```

ç¤ºä¾‹è¾“å‡ºï¼š
```jsonl
{
  "image_path": "1.png",
  "caption": "A bride smiles while the groom points ahead inside a car, their hands resting together on the seat."
}
```