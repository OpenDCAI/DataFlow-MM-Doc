---
title: ç›¸ä¼¼åº¦è¿‡æ»¤ï¼ˆClipFilterï¼‰
createTime: 2025/10/15 15:48:32
icon: material-symbols-light:image
permalink: /zh/mm_operators/vmea8ovk/
---
## ğŸ“˜ æ¦‚è¿°
`ClipFilter` æ˜¯ä¸€ä¸ªåŸºäº **CLIP ç›¸ä¼¼åº¦** çš„å›¾æ–‡ä¸€è‡´æ€§è¿‡æ»¤ç®—å­ã€‚å¯¹æ¯æ¡æ ·æœ¬è®¡ç®—å›¾ç‰‡ä¸æ–‡æœ¬çš„å½’ä¸€åŒ–åµŒå…¥ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆæ˜ å°„åˆ° `[0,1]` èŒƒå›´å†…ï¼‰ï¼Œå½“ç›¸ä¼¼åº¦ **â‰¥ é˜ˆå€¼**ï¼ˆ`threshold`ï¼‰æ—¶ä¿ç•™è¯¥æ ·æœ¬ï¼Œå¦åˆ™è¿‡æ»¤æ‰ã€‚


## ```__init__```å‡½æ•°
```python
def __init__(
    self,
    model_name: str = "../ckpt/clip-vit-base-patch32",
    device: str = None
)
```

## `init`å‚æ•°è¯´æ˜
| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| `model_name` | `str` | `"../ckpt/clip-vit-base-patch32"` | CLIP æ¨¡å‹æœ¬åœ°è·¯å¾„æˆ– Hugging Face Model IDã€‚å†…éƒ¨ä»¥ `CLIPProcessor` / `CLIPModel` åŠ è½½ï¼ˆ`use_safetensors=True`, `weights_only=False`ï¼‰ã€‚ |
| `device` | `str \| None` | `None` | æ¨ç†è®¾å¤‡ï¼›`None` æ—¶è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„ `"cuda"`ï¼Œå¦åˆ™å›é€€åˆ° `"cpu"`ã€‚ |





## `run`å‡½æ•°
```python
def run(
    self,
    storage: DataFlowStorage,
    image_key: str = "image",
    caption_key: str = "caption",
    threshold: float = 0.25
):
    ...
```
æ‰§è¡Œç®—å­ä¸»é€»è¾‘ï¼šä» storage è¯»å–æ•°æ®è¡¨ï¼ŒæŒ‰è¡Œè®¡ç®— CLIP å›¾æ–‡ç›¸ä¼¼åº¦ï¼Œä»…ä¿ç•™ç›¸ä¼¼åº¦ â‰¥ threshold çš„æ ·æœ¬è¡Œï¼Œå¹¶å†™å›å­˜å‚¨ã€‚
å‚æ•°
| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| `storage` | `DataFlowStorage` | æ—  | Dataflow çš„è¯»å†™å­˜å‚¨å¯¹è±¡ã€‚ |
| `image_key` | `str` | `"image"` | å›¾ç‰‡è·¯å¾„åˆ—åã€‚ |
| `caption_key` | `str` | `"caption"` | æ–‡æœ¬æè¿°åˆ—åã€‚ |
| `threshold` | `float` | `0.25` | å›¾æ–‡ç›¸ä¼¼åº¦é˜ˆå€¼ï¼›æ ·æœ¬ç›¸ä¼¼åº¦ **<** è¯¥å€¼å°†è¢«è¿‡æ»¤ã€‚ |




## ğŸ§  ç¤ºä¾‹ç”¨æ³•

```python
from dataflow.utils.storage import FileStorage
from dataflow.operators.core_vision import ClipFilter

# 1) å‡†å¤‡ FileStorageï¼ˆè‡³å°‘åŒ…å« image ä¸ caption åˆ—ï¼‰
storage = FileStorage(
    first_entry_file_name="data/clip_filter_input.jsonl",
    cache_path="./cache_local",
    file_name_prefix="clip_filter",
    cache_type="jsonl"
)

# 2) åˆå§‹åŒ–ç®—å­ï¼ˆå¯ç”¨æœ¬åœ°æˆ–HFæ¨¡å‹ï¼‰
flt = ClipFilter(
    model_name="../ckpt/clip-vit-base-patch32",  # æˆ– "openai/clip-vit-base-patch32"
    device=None                                  # è‡ªåŠ¨é€‰æ‹©cuda/cpu
)

# 3) æ‰§è¡Œè¿‡æ»¤ï¼ˆå°†åªä¿ç•™ç›¸ä¼¼åº¦â‰¥0.25çš„æ ·æœ¬ï¼‰
cols = flt.run(
    storage=storage.step(),
    image_key="image",
    caption_key="caption",
    threshold=0.25
)
print(cols)  # ["image", "caption"]
```

### ğŸ§¾ é»˜è®¤è¾“å‡ºæ ¼å¼ï¼ˆOutput Formatï¼‰
| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| `image` | `string` | æ—  | è¿‡æ»¤åä¿ç•™æ ·æœ¬çš„å›¾ç‰‡è·¯å¾„ã€‚ |
| `caption` | `string` | æ—  | è¿‡æ»¤åä¿ç•™æ ·æœ¬çš„æ–‡æœ¬æè¿°ï¼ˆå›¾æ–‡ç›¸ä¼¼åº¦ â‰¥ `threshold`ï¼‰ã€‚ |


ç¤ºä¾‹è¾“å…¥ï¼š
```jsonl
{
  "image": "1.png",
  "caption": "A bride and groom smiling in a car."
}
{
  "image": "2.jpg",
  "caption": "A red bus driving across a snowy mountain road at night."
}
```

ç¤ºä¾‹è¾“å‡ºï¼š
```jsonl
{
  "image": "1.png",
  "caption": "A bride and groom smiling in a car."
}
```